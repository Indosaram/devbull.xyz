---
title: "01-Probability and Random Variables: A Review (4/5)"
images: ["https://images.unsplash.com/photo-1582480553944-ba71a317a826?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ"]
date: "2020-09-07T12:12:41.000Z"
tags: ['estimation']
---

<TOCInline toc={props.toc} asDisclosure />
## 다변수 정규 확률밀도함수(Multivariate Normal Density Function)

일변수, 이변수 정규 확률변수로부터 확률밀도함수를 계산하는 과정을 지난 포스팅들을 통해서 다루었다. 이번 섹션에서는 다변수 정규확률밀도함수를 구해볼 예정인데, 이전까지와는 다르게 벡터와 행렬 노테이션이 필요하다. 변수 자체가 $n$개이기 때문에 일반적인 연립방정식 꼴로 표기하기 힘들기 때문이다.

먼저 $n$개의 확률변수 $X_1, X_2, \cdots, X_n$에 대해 벡터 $\bf{X}$와 그 실현 $\bf{x}$를 다음과 같이 정의한다.

$$
\bf{X}=
\begin{bmatrix}
X_1 \\\\\\ X_2 \\\\\\ \vdots \\\\\\ X_n
\end{bmatrix}
, \
\bf{x}=
\begin{bmatrix}{l}
x_1 \\\\\\ x_2 \\\\\\ \vdots \\\\\\ x_n
\end{bmatrix}
$$
마찬가지로 평균 벡터 $\bf{m}$은 다음과 같다.
$$
\bf{m}=
\begin{bmatrix}
m_1 \\ m_2 \\ \vdots \\ m_n
\end{bmatrix}
$$
각 확률변수의 분산과 공분산들은 다음과 같이 공분산 행렬(Covariance Matrix)를 정의한다.
$$
\bf{C} = \begin{bmatrix}
E[(X_1-m_1)^2] & E[(X_1-m_1)(X_2-m_2)] & \cdots \\\\\\
E[(X_2-m_2)(X_1-m_1)] & \ddots & \\\\\\
\vdots & & E[(X_n-m_n)^2]
\end{bmatrix}
$$
일변수 및 이변수 정규확률밀도함수에서와 마찬가지로, 모든 확률변수가 아래 식을 만족하면 jointly normal, jointly Gaussian이다.
$$
f_X(\bf{x})=\frac{1}{(2\pi)^{n/2}|\bf{C}|^{1/2}}\exp\left\\{-\frac{1}{2}\left[(\bf{x} - \bf{m})^T\bf{C}^{-1}(\bf{X} - \bf{m})\right]\right\\}
$$
당연하지만 위 식이 성립하려면 $\bf{C}$가 역행렬이 존재해야 한다(Must be nonsingular).



## 정규확률변수의 선형변환과 일반적 성질(Linear Transformation and General Properties of Normal Random Variables)

### 정규확률변수의 선형변환

이제 확률변수 $X_1, X_2, \cdots, X_n$을 선형변환한 $Y_1, Y_2, \cdots, Y_n$을 정의하자. 이제 두 확률변수의 관계는 $\bf{y}=\bf{A}\bf{x}+\bf{b}$와 같다. 이때 $\bf{A}$는 Nonsingular한 정사각행렬이다. 이전 포스팅에서 다루었던 확률변수의 변환을 응용하면 다음과 같이 표기할 수 있다.
$$
f_Y(\bf{y})=f_X(\bf{x}(\bf{y}))\left| J\left( \frac{\bf{x}}{\bf{y}} \right)\right|
$$
두 확률변수 사이의 선형변환 관계식을 이용하면
$$
\bf{x}=\bf{A}^{-1}\bf{y}-A^{-1}\bf{b}
$$
과 같고, 이때 역행렬 $\bf{A}^{-1}$를 원소로 나타내면 다음과 같다.
$$
\bf{A}^{-1}=\begin{bmatrix}
d_{11} & d_{12} & \cdots & d_{1n} \\\\\\
d_{21} & d_{22} & \cdots & d_{2n} \\\\\\
\vdots & \vdots & \ddots & \vdots \\\\\\
d_{n1} & d_{n2} & \cdots & d_{nn}
\end{bmatrix}
$$
위 선형변환 관계식에 대입하면
$$
\begin{align}
x_1 &= (d_{11}y_1+d_{12}y_2+\cdots)-(d_{11}b_1+d_{12}b_2+\cdots)\\\\\\
x_2 &= (d_{21}y_1+d_{22}y_2+\cdots)-(d_{21}b_1+d_{22}b_2+\cdots)\\\\\\
&\vdots
\end{align}
$$
과 같다. 자코비안을 다시 구해보자.
$$
\begin{aligned}
J\left(\frac{\bf{x}}{\bf{y}}\right)&=J\left( \frac{x_1,x_2,\cdots}{y_1, y_2, \cdots} \right)\\\\\\
&=Det
\begin{bmatrix}
\frac{\partial x_1}{\partial y_1} & \frac{\partial x_2}{\partial y_1} & \cdots\\\\\\
 \frac{\partial x_1}{\partial y_2} &  \frac{\partial x_2}{\partial y_2} & \cdots \\\\\\
 \vdots
\end{bmatrix}\\\\\\
&=Det
\begin{bmatrix}
d_{11} & d_{21} & \cdots\\\\\\
 d_{12} &  d_{22} & \cdots \\\\\\
 \vdots
\end{bmatrix}\\\\\\
&=Det(\bf{A}^{-1})^T=Det(\bf{A}^{-1})
\end{aligned}
$$
자코비안은 원래 행렬인 $\bf{A}^{-1}$의 행렬식과 같은 결과가 나온다. 이제 원래 구하고자 했던 식에 자코비안을 대입하자.
$$
\begin{aligned}
f_Y(\bf{y})&=f_X({\bf x}({\bf y}))\left| J\left( \frac{{\bf x}}{{\bf y}} \right)\right|\\\\\\
&=\frac{|Det(\bf{A}^{-1})|}{(2\pi)^{n/2}|\bf{C}_X|^{1/2}}\\\\\\
&\times \exp\left\\{
{-\frac{1}{2}\left[ (\bf{A}^{-1}\bf{y}-\bf{A}^{-1}\bf{b}-\bf{m}_X)^T \bf{C}_X^{-1} (\bf{A}^{-1}\bf{y}-\bf{A}^{-1}\bf{b}-\bf{m_X}) \right]}
\right\\}\\\\\\
\end{aligned}
$$

위 식의 지수 부분만 떼어서 정리하면 다음과 같다.
$$
\begin{aligned}
&
{-\frac{1}{2}\left[ (\bf{A}^{-1}\bf{y}-\bf{A}^{-1}\bf{b}-\bf{m_X})^T \bf{C}_X^{-1} (\bf{A}^{-1}\bf{y}-\bf{A}^{-1}\bf{b}-\bf{m_X}) \right]}\\\\\\
&={-\frac{1}{2}\left[ (\bf{y}-\bf{m_Y})^T(\bf{A}^{-1}) \bf{C}_X^{-1}  (\bf{A}^{-1})^T(\bf{y}-\bf{m_Y}) \right]}\\\\\\
&={-\frac{1}{2}\left[ (\bf{y}-\bf{m_Y})^T(\bf{A} \bf{C}_X \bf{A}^T)^{-1}(\bf{y}-\bf{m}_Y) \right]}\\\\\\
\end{aligned}
$$

마지막으로 $\bf{A}^{-1}$의 행렬식을 구해야 하는데,
$$
|Det(\bf{A}^{-1})|=\frac{1}{|Det(\bf{A})|}=\frac{1}{|Det(\bf{A})|^{1/2}\cdot|Det(\bf{A}^T)|^{1/2}}
$$
임을 이용할 수 있다. 이제 구한 식을 $f_Y(y)$에 대입하면,
$$
f_Y(\bf{y})
=\frac{1}{(2\pi)^{n/2}|\bf{A}\bf{C}_X\bf{A}^T|^{1/2}}
\exp\bigg[
-\frac{1}{2}
\Big[
(\bf{y}-\bf{m_Y})^T(\bf{A} \bf{C}_X \bf{A}^T)^{-1}(\bf{y}-\bf{m}_Y) 
\Big]
\bigg]
$$
과 같이 정리할 수 있다. 따라서 선형변환된 $Y$의 평균과 분산은
$$
\bf{m}_Y=\bf{A}\bf{m}_X+\bf{b}\\
\bf{C}_Y=\bf{A}\bf{C}_X\bf{A}^T
$$
과 같다.  또한 $f_Y(y)$의 형태로부터 정규성(Normality)는 선형변환을 거쳐도 보존된다는 것을 알 수 있다. 여기서 중요한 사실은 오직 평균과 공분산의 값만 변한다는 점이다. 이후 칼만필터 식을 유도하는데 중요하게 쓰이는 성질이므로 반드시 알아두자.

그런데 여기서 중요한 사실은 $\bf{C}_X$가 Positive definite이면 정사각행렬의 대각화가 가능해지고, 그에 따라 확률변수를 Decoupling할수 있다는 것이다. 이변수의 경우를 가지고 한번 살펴보자. $\bf{C}$가 대칭행렬(Symmetric)이 Positive definite이려면 $\bf{x}^T\bf{C}\bf{x}$가 모든 0벡터가 아닌 $\bf{x}$에 대해 0보다 큰 값을 가져야 한다.
$$
\begin{bmatrix}
x1 & x2
\end{bmatrix}
$$

$$
\begin{bmatrix}
c_{11} & c_{12} \\ c_{21} & c_{22}
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=c_{11}x_1^2+2c_{12}x_1x_2+c_{22}x_2^2
$$
이때 $\bf{C}$가 공분산 행렬이라면,
$$
c_{11}=\sigma_1^2, \ c_{12}=\rho\sigma_1\sigma_2, \ c_{22}=\sigma_2^2
$$
이므로
$$
{\bf x^TC x}=(\sigma_1 x_1)^2+2\rho(\sigma_1x_1)+(\sigma_2x_2)^2
$$
이다. 따라서 $|\rho| <1$이면 준식이 항상 0보다 크기 때문에 Postitive definete하게 된다.

### 정리

1. 벡터 확률변수 $\bf{X}$는 평균 벡터와 공분산 행렬로 완벽하게 정의 가능하다.
2.  $|\rho| <1$이면 $\bf X$의 공분산행렬 ${\bf C}$는 항상 Positive definite하다.
3. 어떤 정규확률변수가 서로 Uncorrelated되어 있다면, 통계적으로도 서로 독립이다.
4. 정규확률변수의 선형변환 결과 역시 정규확률변수이다. 공분산행렬이 Positive definite이면 항상 대각화를 통한 Decoupling이 가능하다.
5. Joint 확률밀도함수가 정규확률밀도함수라면, 모든 Marginal과 Conditional 확률밀도함수 역시 정규확률밀도함수다 (If the joint density function for n random variables is normal in form, all
   marginal and conditional densities associated with the n variates will also be
   normal in form.)
